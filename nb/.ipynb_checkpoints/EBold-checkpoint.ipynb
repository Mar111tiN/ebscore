{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T19:54:20.752349Z",
     "start_time": "2020-09-05T19:54:20.628703Z"
    }
   },
   "outputs": [],
   "source": [
    "ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T19:54:35.947879Z",
     "start_time": "2020-09-05T19:54:35.826867Z"
    }
   },
   "outputs": [],
   "source": [
    "home = '/Users/mahtin'\n",
    "testdata = f\"{home}/Dropbox/Icke/Work/somVar/testdata\"\n",
    "pon_path = f\"{testdata}/testpon\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezing all data and shell paths into config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T20:57:53.753600Z",
     "start_time": "2020-09-05T20:57:53.750278Z"
    }
   },
   "outputs": [],
   "source": [
    "EBconfig = {\n",
    "    \"cleanpileup\": \"../shell/cleanpileup.mawk\",\n",
    "    \"makeponlist\": \"../shell/makeponlist.sh\",\n",
    "    \"csv2bed\":\"../shell/csv2bed.mawk\",\n",
    "    \"pon2cols\": \"../shell/pon2cols.mawk\",\n",
    "    \"pile2count\": \"../shell/pile2count2.mawk\",\n",
    "    \"filterVar\": \"../shell/filterVar.mawk\",\n",
    "    \"pon2tumor\": \"../shell/pon2tumor.mawk\",\n",
    "    \"pon_path\": pon_path,\n",
    "    \"genome_split\": \"/Users/mahtin/Dropbox/Icke/Work/static/genome/gatk/hg38/split\",\n",
    "    \"MAPQ\": 20,\n",
    "    \"Q\": 25,\n",
    "    \"fit_pen\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_file = f\"{testdata}/bam/002_A.bam\"\n",
    "mut_file = \"../data/002.csv\"\n",
    "pon_list = \"Pon_chr7short.txt\"\n",
    "chrom = \"chr7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the matrix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the EB.matrix file\n",
    "eb_matrix = pd.read_csv('../data/002_A-B-chr1.EBmutmatrix', sep='\\t').iloc[:30,:]\n",
    "row = eb_matrix.iloc[1,:]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_df(row):\n",
    "    '''\n",
    "    converts the base-wise read coverage to a matrix\n",
    "    '''\n",
    "\n",
    "    matrix = pd.DataFrame()\n",
    "    matrix['depth_p'] = np.array(row['depthP'].split('|')).astype(int)\n",
    "    matrix['mm_p'] = np.array(row['misP'].split('|')).astype(int)\n",
    "    matrix['depth_n'] = np.array(row['depthN'].split('|')).astype(int)\n",
    "    matrix['mm_n'] = np.array(row['misN'].split('|')).astype(int)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin_l_bfgs_b as minimize_func\n",
    "from scipy.stats import chi2\n",
    "from scipy.special import gammaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_combination(p_values):\n",
    "\n",
    "    if 0 in p_values.values():\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - chi2.cdf(sum([-2 * math.log(x) for x in p_values.values()]), 2 * len(p_values.values()))\n",
    "\n",
    "\n",
    "def bb_pvalue(params, target_df):\n",
    "    n_minus_k = target_df[0] - target_df[1]\n",
    "    # get the list of observations [n, k] to [n, n]\n",
    "    obs_list = [target_df + np.array([0, i])\n",
    "                for i in range(0, n_minus_k + 1)]\n",
    "    # get the list of loglikelihoods per observation\n",
    "    ll_list = [bb_loglikelihood(params, obs, True) for obs in obs_list]\n",
    "\n",
    "    #######################################################\n",
    "    # print(f'ab: {params}\\n observations: {obs_list} ll {ll_list}\\n')\n",
    "    #######################################################\n",
    "\n",
    "    # get the sum of exponentials of loglikelihoods (densities) per observation\n",
    "\n",
    "    p_value = sum([math.exp(ll) for ll in ll_list])\n",
    "\n",
    "    return p_value\n",
    "\n",
    "       \n",
    "def bb_pvalues(params, target_df):\n",
    "    '''\n",
    "    accumulate p_value of target observation falling in fitted bb_distribution (not a variant)\n",
    "    p_values are computed per strand (pvalue_p and pvalue_n)\n",
    "    p_value: exponential sum of loglikelihooks of successes greater or equal than observed\n",
    "    [n, k] --> sum of density (exp of loglikelihood) [n, k] to [n, n]\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    target_p = target_df.loc[['depth_p', 'mm_p']]\n",
    "    target_n = target_df.loc[['depth_n', 'mm_n']]\n",
    "    p_values = {}\n",
    "    p_values['p'] = bb_pvalue(params['p'], target_p)\n",
    "    p_values['n'] = bb_pvalue(params['n'], target_n)\n",
    "    return p_values\n",
    "\n",
    "\n",
    "# the matrices for beta-binomial calculation\n",
    "KS_matrix = np.array([[1, 0, 1, 1, 0, 1, 0, 0, 0], [\n",
    "                     0, 1, -1, 0, 1, -1, 0, 0, 0]])\n",
    "gamma_reduce = np.array([1, -1, -1, -1, 1, 1, 1, -1, -1])\n",
    "\n",
    "\n",
    "def bb_loglikelihood(params, count_df, is_1d):\n",
    "    [a, b] = params\n",
    "    ab_matrix = np.array([1, 1, 1, a + b, a, b, a + b, a, b])\n",
    "    # convert df into matrix for np.array operations that change dims\n",
    "    count_matrix = count_df.values\n",
    "    # perform matrix multiplication to get inputs to log-gamma\n",
    "    input_matrix = np.matmul(count_matrix, KS_matrix) + ab_matrix\n",
    "    # get corresponding log-gamma values and reduce over pon-values\n",
    "    if is_1d:  # check whether gammatrix is 2-dim - otherwise sum aggregation over axis 0 is faulty\n",
    "        gamma_matrix = gammaln(input_matrix)\n",
    "    else:\n",
    "        gamma_matrix = np.sum(gammaln(input_matrix), axis=0)\n",
    "    # add or subtract using gamma_reduce matrix and sum to loglikelihood (scalar)\n",
    "    log_likelihood = np.sum(gamma_matrix * gamma_reduce)\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def fit_bb(count_df, pen):\n",
    "    '''\n",
    "    Obtaining maximum likelihood estimator of beta-binomial distribution\n",
    "    count_df is the array of depth-mismatch (trials, success) pairs over the PoN list for either strand\n",
    "    during minimization of fitting function (max for loglikelihood) penalty term is applied to constrain alpha and beta\n",
    "        Ref for L-BFGS-B algorithm:\n",
    "        A Limited Memory Algorithm for Bound Constrained Optimization\n",
    "        R. H. Byrd, P. Lu and J. Nocedal. , (1995),\n",
    "        SIAM Journal on Scientific and Statistical Computing, 16, 5, pp. 1190-1208.\n",
    "    '''\n",
    "\n",
    "    def bb_loglikelihood_fitting(params, count_df, penalty):\n",
    "        '''\n",
    "        Fitting params [alpha, beta] to maximize loglikelihood\n",
    "        '''\n",
    "\n",
    "        # Here, we apply the penalty term of alpha and beta (default 0.5 is slightly arbitray...)\n",
    "        result = penalty * \\\n",
    "            math.log(sum(params)) - bb_loglikelihood(params,\n",
    "                                                     count_df, False)  # matrix is dim2\n",
    "        return result\n",
    "\n",
    "    # get the respective control matrices (as dataframe) for positive and negative strands\n",
    "    count_p = count_df.loc[:, ['depth_p', 'mm_p']]\n",
    "    count_n = count_df.loc[:, ['depth_n', 'mm_n']]\n",
    "    # minimize loglikelihood using L-BFGS-B algorithm\n",
    "    ab_p = minimize_func(\n",
    "        bb_loglikelihood_fitting, [20, 20],\n",
    "        args=(count_p, pen), approx_grad=True,\n",
    "        bounds=[(0.1, 10000000), (1, 10000000)]\n",
    "    )[0]\n",
    "    ab_p = [round(param, 5) for param in ab_p]\n",
    "    ab_n = minimize_func(\n",
    "        bb_loglikelihood_fitting, [20, 20],\n",
    "        args=(count_n, pen), approx_grad=True,\n",
    "        bounds=[(0.1, 10000000), (1, 10000000)]\n",
    "    )[0]\n",
    "    ab_n = [round(param, 5) for param in ab_n]\n",
    "    return {'p': ab_p, 'n': ab_n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:44:57.663382Z",
     "start_time": "2020-08-29T13:41:48.470264Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix2EBscore(pen, row):\n",
    "    \n",
    "    count_df = get_count_df(row)\n",
    "    # ########### FITTING ####################################\n",
    "    # get the respective control matrices (as dataframe) for positive and negative strands\n",
    "    # estimate the beta-binomial parameters for positive and negative strands\n",
    "\n",
    "    # <<<<<<######### DEBUG ###############\n",
    "    # print(row['Chr'], row['pos'], count_df)\n",
    "    # <<<<<<###############################\n",
    "\n",
    "    bb_params = fit_bb(count_df[1:], pen)\n",
    "    # evaluate the p-values of target mismatch numbers for positive and negative strands\n",
    "    p_values = bb_pvalues(bb_params, count_df.iloc[0])\n",
    "\n",
    "    # ########### FISHER COMBINATION #########################\n",
    "    # perform Fisher's combination methods for integrating two p-values of positive and negative strands\n",
    "    EB_pvalue = fisher_combination(p_values)\n",
    "    EB_score = 0\n",
    "    if EB_pvalue < 1e-60:\n",
    "        EB_score = 60\n",
    "    elif EB_pvalue > 1.0 - 1e-10:\n",
    "        EB_score = 0\n",
    "    else:\n",
    "        EB_score = -round(math.log10(EB_pvalue), 3)\n",
    "    return EB_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = get_count_df(row)\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_params = fit_bb(count_df[1:], 0.5)\n",
    "bb_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bb_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = count_df.iloc[0]\n",
    "print(target_df)\n",
    "target_p = target_df.loc[['depth_p', 'mm_p']]\n",
    "target_p\n",
    "isinstance(target_p, pd.DataFrame)\n",
    "target_n = target_df.loc[['depth_n', 'mm_n']]\n",
    "target_n\n",
    "p_values = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bb_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = target_p\n",
    "n_minus_k = target_df[0] - target_df[1]\n",
    "n_minus_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_list = [target_df + np.array([0, i])\n",
    "                for i in range(0, n_minus_k + 1)]\n",
    "obs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs_list[0]\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_params['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_list = [bb_loglikelihood(bb_params['p'], obs, True) for obs in obs_list]\n",
    "ll_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[math.exp(ll) for ll in ll_list]\n",
    "\n",
    "p_value = sum([math.exp(ll) for ll in ll_list])\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T05:10:37.283231Z",
     "start_time": "2020-08-24T05:10:33.803157Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from io import StringIO\n",
    "from subprocess import Popen, PIPE, run\n",
    "from HDR_run import HDR_master\n",
    "\n",
    "home = '/Users/mahtin'\n",
    "path = '/Users/martinscience/Dropbox/Icke/Work/somVar/HDRtest'\n",
    "bam_file = f'{path}/data/002.bam '\n",
    "chrom = 'chr1'\n",
    "# chrom = ''\n",
    "pileup_file = f'{path}/data/001.chr1.pileup'\n",
    "threads = 8\n",
    "mut_file = f'{path}/data/002.csv'\n",
    "genome_split_path = os.path.join(home,'Dropbox/Icke/Work/static/genome/gatk/hg38/split')\n",
    "HDR_config = {\n",
    "    \"minAltSum\": 2,\n",
    "    \"minAltRatio\": 0.1,\n",
    "    \"maxAltRatio\": 0.85,\n",
    "    \"MINQ\": 15,\n",
    "    \"MINSIM\": .50,\n",
    "    \"PAD\": 100,\n",
    "    \"MINq\": 10,\n",
    "    \"MinAltSupport\": 5,\n",
    "    \"MinHDRCount\": 1,\n",
    "    \"pile2hotspot\": '../shell/pile2hotspot.mawk',#\n",
    "    \"pile2hotspot_chrom\": '../shell/pile2hotspot_chrom.mawk',\n",
    "    \"editbam\": '../shell/editbam.mawk',\n",
    "    \"bam2csv\": '../shell/bam2csv.mawk',\n",
    "    \"genome_split_path\": genome_split_path # the path to the folder with chrom-split genomes (chr1.fa..)\n",
    "}\n",
    "HDR_master(mut_file, bam_file=bam_file, pileup_file=pileup_file, chrom=chrom, threads=threads, HDR_config=HDR_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:07:32.114469Z",
     "start_time": "2020-08-23T14:07:31.983073Z"
    }
   },
   "outputs": [],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:25:07.814840Z",
     "start_time": "2020-08-23T19:25:07.772067Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "home = '/Users/mahtin'\n",
    "path = '/Users/mahtin/Dropbox/Icke/Work/somVar/HDRtest'\n",
    "bam_file = f'{path}/data/002.bam '\n",
    "chrom = 'chr1'\n",
    "# chrom = ''\n",
    "pileup_file = f'{path}/data/002.pileup'\n",
    "threads = 8\n",
    "mut_file = f'{path}/data/002.csv'\n",
    "mut_df = pd.read_csv(mut_file, sep='\\t').loc[:, [\n",
    "        'Chr', 'Start', 'End', 'Ref', 'Alt', 'Gene']]\n",
    "# make Chr column categorical for sorting .. and sort\n",
    "chrom_list = [f\"chr{i}\" for i in range(23)] + ['chrX', 'chrY']\n",
    "mut_df['Chr'] = pd.Categorical(mut_df['Chr'], chrom_list)\n",
    "mut_df = mut_df.sort_values(['Chr', 'Start'])\n",
    "mut_df = mut_df.query('Chr == @chrom')\n",
    "mut_df\n",
    "mut_split = np.array_split(mut_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:14:23.270088Z",
     "start_time": "2020-08-23T19:14:23.267394Z"
    }
   },
   "outputs": [],
   "source": [
    "mut_df = mut_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:30:19.182347Z",
     "start_time": "2020-08-23T19:30:19.170669Z"
    }
   },
   "outputs": [],
   "source": [
    "anno_df = mut_df.sort_values(['Chr', 'Start']).iloc[0:,:5]\n",
    "anno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:38:46.184923Z",
     "start_time": "2020-08-23T19:38:46.179603Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_regions(df, padding):\n",
    "    '''\n",
    "    takes a mutation list and returns a region list using padding\n",
    "    overlapping regions are reduced to one using the gap strategy\n",
    "    '''\n",
    "\n",
    "    df = df.sort_values('Start')\n",
    "    df['Start'] = df['Start'] - padding\n",
    "    df['End'] = df['End'] + padding\n",
    "    # find the break points\n",
    "    # if Start is greater than previous End (using shift), this is a gap --> df['gap'] = 1\n",
    "    df['gap'] = df['Start'].gt(df['End'].shift()).astype('int')\n",
    "    # id different reads according to gap\n",
    "    # cumulative sum does not increase at df['gap'] == 0 and so these consecutive stretches are grouped together\n",
    "    df['gap'] = df['gap'].cumsum()\n",
    "    # groupby the coverage break group and condense individual coverage islands\n",
    "    # agg has to contain the neccessary shared columns TransLength because it is needed for coverage computation\n",
    "    df = df.groupby('gap').agg({'Chr':'first','Start': 'min', 'End':'max'})\n",
    "    return df.reset_index('gap').drop(columns='gap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:37:26.582555Z",
     "start_time": "2020-08-23T19:37:26.547975Z"
    }
   },
   "outputs": [],
   "source": [
    "df = anno_df\n",
    "anno_df\n",
    "padding = 100\n",
    "df['Start'] = df['Start'] - padding\n",
    "df['End'] = df['End'] + padding\n",
    "df['gap'] = df['Start'].gt(df['End'].shift()).astype('int')\n",
    "df['gap'] = df['gap'].cumsum()\n",
    "df = df.groupby('gap').agg({'Chr':'first','Start': 'min', 'End':'max'}).reset_index().drop(columns='gap')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:38:49.099313Z",
     "start_time": "2020-08-23T19:38:49.076795Z"
    }
   },
   "outputs": [],
   "source": [
    "bed_df = reduce_regions(anno_df, 100)\n",
    "bed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=[\n",
    "        'Chr',\n",
    "        'Start',\n",
    "        'End',\n",
    "        'Ref',\n",
    "        'Alt',\n",
    "        'Gene',\n",
    "        'HDRcand',\n",
    "        'HDRcount',\n",
    "        'HDRinfo',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
