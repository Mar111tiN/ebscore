{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T19:54:20.752349Z",
     "start_time": "2020-09-05T19:54:20.628703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001_A-B-chr1.EB           002_chr7.bed              test.bed\r\n",
      "001_A-B-chr1.mutmatrix    002_chr7.pon              test.cleanpileup\r\n",
      "002.csv                   003_A-B-chr1.EB           test.cutpileup\r\n",
      "002_A-B-chr1.EB           003_A-B-chr1.mutmatrix    test.filterCount\r\n",
      "002_A-B-chr1.EBmutmatrix  chr7.pilecount.gz         test.pileup\r\n",
      "002_A-B-chr1.mutmatrix    stop.file                 test.pon\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T19:54:35.947879Z",
     "start_time": "2020-09-05T19:54:35.826867Z"
    }
   },
   "outputs": [],
   "source": [
    "home = '/Users/mahtin'\n",
    "testdata = f\"{home}/Dropbox/Icke/Work/somVar/testdata\"\n",
    "pon_path = f\"{testdata}/testpon\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezing all data and shell paths into config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-05T20:57:53.753600Z",
     "start_time": "2020-09-05T20:57:53.750278Z"
    }
   },
   "outputs": [],
   "source": [
    "EBconfig = {\n",
    "    \"cleanpileup\": \"../shell/cleanpileup.mawk\",\n",
    "    \"makeponlist\": \"../shell/makeponlist.sh\",\n",
    "    \"csv2bed\":\"../shell/csv2bed.mawk\",\n",
    "    \"pon2cols\": \"../shell/pon2cols.mawk\",\n",
    "    \"pile2count\": \"../shell/pile2count2.mawk\",\n",
    "    \"filterVar\": \"../shell/filterVar.mawk\",\n",
    "    \"pon2tumor\": \"../shell/pon2tumor.mawk\",\n",
    "    \"pon_path\": pon_path,\n",
    "    \"genome_split\": \"/Users/mahtin/Dropbox/Icke/Work/static/genome/gatk/hg38/split\",\n",
    "    \"MAPQ\": 20,\n",
    "    \"Q\": 25,\n",
    "    \"fit_pen\": 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_file = f\"{testdata}/bam/002_A.bam\"\n",
    "mut_file = \"../data/002.csv\"\n",
    "pon_list = \"Pon_chr7short.txt\"\n",
    "chrom = \"chr7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the matrix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chr                                                    chr1\n",
       "Start                                                 16957\n",
       "End                                                   16957\n",
       "Ref                                                       G\n",
       "Alt                                                       T\n",
       "depthP    12|45|63|45|31|5|23|20|34|33|32|23|18|29|14|13...\n",
       "misP      0|0|0|0|1|0|0|0|0|0|0|0|1|0|0|1|0|0|0|0|0|0|0|...\n",
       "depthN    42|78|169|110|79|29|80|69|118|18|77|35|115|67|...\n",
       "misN      5|0|21|0|12|0|0|0|24|0|0|0|25|0|19|15|0|5|0|10...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the EB.matrix file\n",
    "eb_matrix = pd.read_csv('../data/002_A-B-chr1.EBmutmatrix', sep='\\t').iloc[:30,:]\n",
    "row = eb_matrix.iloc[1,:]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_df(row):\n",
    "    '''\n",
    "    converts the base-wise read coverage to a matrix\n",
    "    '''\n",
    "\n",
    "    matrix = pd.DataFrame()\n",
    "    matrix['depth_p'] = np.array(row['depthP'].split('|')).astype(int)\n",
    "    matrix['mm_p'] = np.array(row['misP'].split('|')).astype(int)\n",
    "    matrix['depth_n'] = np.array(row['depthN'].split('|')).astype(int)\n",
    "    matrix['mm_n'] = np.array(row['misN'].split('|')).astype(int)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin_l_bfgs_b as minimize_func\n",
    "from scipy.stats import chi2\n",
    "from scipy.special import gammaln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_combination(p_values):\n",
    "\n",
    "    if 0 in p_values.values():\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - chi2.cdf(sum([-2 * math.log(x) for x in p_values.values()]), 2 * len(p_values.values()))\n",
    "\n",
    "\n",
    "def bb_pvalue(params, target_df):\n",
    "    n_minus_k = target_df[0] - target_df[1]\n",
    "    # get the list of observations [n, k] to [n, n]\n",
    "    obs_list = [target_df + np.array([0, i])\n",
    "                for i in range(0, n_minus_k + 1)]\n",
    "    # get the list of loglikelihoods per observation\n",
    "    ll_list = [bb_loglikelihood(params, obs, True) for obs in obs_list]\n",
    "\n",
    "    #######################################################\n",
    "    # print(f'ab: {params}\\n observations: {obs_list} ll {ll_list}\\n')\n",
    "    #######################################################\n",
    "\n",
    "    # get the sum of exponentials of loglikelihoods (densities) per observation\n",
    "\n",
    "    p_value = sum([math.exp(ll) for ll in ll_list])\n",
    "\n",
    "    return p_value\n",
    "\n",
    "       \n",
    "def bb_pvalues(params, target_df):\n",
    "    '''\n",
    "    accumulate p_value of target observation falling in fitted bb_distribution (not a variant)\n",
    "    p_values are computed per strand (pvalue_p and pvalue_n)\n",
    "    p_value: exponential sum of loglikelihooks of successes greater or equal than observed\n",
    "    [n, k] --> sum of density (exp of loglikelihood) [n, k] to [n, n]\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    target_p = target_df.loc[['depth_p', 'mm_p']]\n",
    "    target_n = target_df.loc[['depth_n', 'mm_n']]\n",
    "    p_values = {}\n",
    "    p_values['p'] = bb_pvalue(params['p'], target_p)\n",
    "    p_values['n'] = bb_pvalue(params['n'], target_n)\n",
    "    return p_values\n",
    "\n",
    "\n",
    "# the matrices for beta-binomial calculation\n",
    "KS_matrix = np.array([[1, 0, 1, 1, 0, 1, 0, 0, 0], [\n",
    "                     0, 1, -1, 0, 1, -1, 0, 0, 0]])\n",
    "gamma_reduce = np.array([1, -1, -1, -1, 1, 1, 1, -1, -1])\n",
    "\n",
    "\n",
    "def bb_loglikelihood(params, count_df, is_1d):\n",
    "    [a, b] = params\n",
    "    ab_matrix = np.array([1, 1, 1, a + b, a, b, a + b, a, b])\n",
    "    # convert df into matrix for np.array operations that change dims\n",
    "    count_matrix = count_df.values\n",
    "    # perform matrix multiplication to get inputs to log-gamma\n",
    "    input_matrix = np.matmul(count_matrix, KS_matrix) + ab_matrix\n",
    "    # get corresponding log-gamma values and reduce over pon-values\n",
    "    if is_1d:  # check whether gammatrix is 2-dim - otherwise sum aggregation over axis 0 is faulty\n",
    "        gamma_matrix = gammaln(input_matrix)\n",
    "    else:\n",
    "        gamma_matrix = np.sum(gammaln(input_matrix), axis=0)\n",
    "    # add or subtract using gamma_reduce matrix and sum to loglikelihood (scalar)\n",
    "    log_likelihood = np.sum(gamma_matrix * gamma_reduce)\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def fit_bb(count_df, pen):\n",
    "    '''\n",
    "    Obtaining maximum likelihood estimator of beta-binomial distribution\n",
    "    count_df is the array of depth-mismatch (trials, success) pairs over the PoN list for either strand\n",
    "    during minimization of fitting function (max for loglikelihood) penalty term is applied to constrain alpha and beta\n",
    "        Ref for L-BFGS-B algorithm:\n",
    "        A Limited Memory Algorithm for Bound Constrained Optimization\n",
    "        R. H. Byrd, P. Lu and J. Nocedal. , (1995),\n",
    "        SIAM Journal on Scientific and Statistical Computing, 16, 5, pp. 1190-1208.\n",
    "    '''\n",
    "\n",
    "    def bb_loglikelihood_fitting(params, count_df, penalty):\n",
    "        '''\n",
    "        Fitting params [alpha, beta] to maximize loglikelihood\n",
    "        '''\n",
    "\n",
    "        # Here, we apply the penalty term of alpha and beta (default 0.5 is slightly arbitray...)\n",
    "        result = penalty * \\\n",
    "            math.log(sum(params)) - bb_loglikelihood(params,\n",
    "                                                     count_df, False)  # matrix is dim2\n",
    "        return result\n",
    "\n",
    "    # get the respective control matrices (as dataframe) for positive and negative strands\n",
    "    count_p = count_df.loc[:, ['depth_p', 'mm_p']]\n",
    "    count_n = count_df.loc[:, ['depth_n', 'mm_n']]\n",
    "    # minimize loglikelihood using L-BFGS-B algorithm\n",
    "    ab_p = minimize_func(\n",
    "        bb_loglikelihood_fitting, [20, 20],\n",
    "        args=(count_p, pen), approx_grad=True,\n",
    "        bounds=[(0.1, 10000000), (1, 10000000)]\n",
    "    )[0]\n",
    "    ab_p = [round(param, 5) for param in ab_p]\n",
    "    ab_n = minimize_func(\n",
    "        bb_loglikelihood_fitting, [20, 20],\n",
    "        args=(count_n, pen), approx_grad=True,\n",
    "        bounds=[(0.1, 10000000), (1, 10000000)]\n",
    "    )[0]\n",
    "    ab_n = [round(param, 5) for param in ab_n]\n",
    "    return {'p': ab_p, 'n': ab_n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-29T13:44:57.663382Z",
     "start_time": "2020-08-29T13:41:48.470264Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix2EBscore(pen, row):\n",
    "    \n",
    "    count_df = get_count_df(row)\n",
    "    # ########### FITTING ####################################\n",
    "    # get the respective control matrices (as dataframe) for positive and negative strands\n",
    "    # estimate the beta-binomial parameters for positive and negative strands\n",
    "\n",
    "    # <<<<<<######### DEBUG ###############\n",
    "    # print(row['Chr'], row['pos'], count_df)\n",
    "    # <<<<<<###############################\n",
    "\n",
    "    bb_params = fit_bb(count_df[1:], pen)\n",
    "    # evaluate the p-values of target mismatch numbers for positive and negative strands\n",
    "    p_values = bb_pvalues(bb_params, count_df.iloc[0])\n",
    "\n",
    "    # ########### FISHER COMBINATION #########################\n",
    "    # perform Fisher's combination methods for integrating two p-values of positive and negative strands\n",
    "    EB_pvalue = fisher_combination(p_values)\n",
    "    EB_score = 0\n",
    "    if EB_pvalue < 1e-60:\n",
    "        EB_score = 60\n",
    "    elif EB_pvalue > 1.0 - 1e-10:\n",
    "        EB_score = 0\n",
    "    else:\n",
    "        EB_score = -round(math.log10(EB_pvalue), 3)\n",
    "    return EB_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth_p</th>\n",
       "      <th>mm_p</th>\n",
       "      <th>depth_n</th>\n",
       "      <th>mm_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth_p  mm_p  depth_n  mm_n\n",
       "0        12     0       42     5\n",
       "1        45     0       78     0\n",
       "2        63     0      169    21\n",
       "3        45     0      110     0\n",
       "4        31     1       79    12\n",
       "5         5     0       29     0\n",
       "6        23     0       80     0\n",
       "7        20     0       69     0\n",
       "8        34     0      118    24\n",
       "9        33     0       18     0\n",
       "10       32     0       77     0\n",
       "11       23     0       35     0\n",
       "12       18     1      115    25\n",
       "13       29     0       67     0\n",
       "14       14     0       65    19\n",
       "15       13     1       55    15\n",
       "16        6     0       14     0\n",
       "17        3     0       27     5\n",
       "18       10     0       21     0\n",
       "19       16     0       72    10\n",
       "20       13     0       34     3\n",
       "21        9     0       37    12\n",
       "22        6     0       26     0\n",
       "23        9     0       26     0\n",
       "24        6     0       26     4\n",
       "25        4     0       10     0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = get_count_df(row)\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': [0.20509, 23.07746], 'n': [0.22661, 2.47235]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_params = fit_bb(count_df[1:], 0.5)\n",
    "bb_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bb_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth_p    12\n",
      "mm_p        0\n",
      "depth_n    42\n",
      "mm_n        5\n",
      "Name: 0, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "depth_p    12\n",
       "mm_p        0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "depth_n    42\n",
       "mm_n        5\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df = count_df.iloc[0]\n",
    "print(target_df)\n",
    "target_p = target_df.loc[['depth_p', 'mm_p']]\n",
    "target_p\n",
    "isinstance(target_p, pd.DataFrame)\n",
    "target_n = target_df.loc[['depth_n', 'mm_n']]\n",
    "target_n\n",
    "p_values = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bb_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df = target_p\n",
    "n_minus_k = target_df[0] - target_df[1]\n",
    "n_minus_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[depth_p    12\n",
       " mm_p        0\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        1\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        2\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        3\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        4\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        5\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        6\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        7\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        8\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p        9\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p       10\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p       11\n",
       " Name: 0, dtype: int64,\n",
       " depth_p    12\n",
       " mm_p       12\n",
       " Name: 0, dtype: int64]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_list = [target_df + np.array([0, i])\n",
    "                for i in range(0, n_minus_k + 1)]\n",
    "obs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth_p    12\n",
       "mm_p        0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = obs_list[0]\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20509, 23.07746]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_params['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.08708843497620222,\n",
       " -2.71512432565185,\n",
       " -4.322674064115681,\n",
       " -5.796086538203646,\n",
       " -7.256898948463835,\n",
       " -8.754375676957544,\n",
       " -10.320551307742598,\n",
       " -11.984299183812333,\n",
       " -13.778216739844545,\n",
       " -15.745463602335015,\n",
       " -17.951649249447676,\n",
       " -20.514786859406364,\n",
       " -23.72218175343587]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_list = [bb_loglikelihood(bb_params['p'], obs, True) for obs in obs_list]\n",
    "ll_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9165960329004581,\n",
       " 0.06619672254477434,\n",
       " 0.013264366309962802,\n",
       " 0.0030394261792586028,\n",
       " 0.0007052917940841681,\n",
       " 0.00015776946433032388,\n",
       " 3.294894526343216e-05,\n",
       " 6.241442803424289e-06,\n",
       " 1.0379979586463286e-06,\n",
       " 1.4515501416863553e-07,\n",
       " 1.598445340206159e-08,\n",
       " 1.2318030342587887e-09,\n",
       " 4.984107097409842e-11]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0000000000000056"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[math.exp(ll) for ll in ll_list]\n",
    "\n",
    "p_value = sum([math.exp(ll) for ll in ll_list])\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T05:10:37.283231Z",
     "start_time": "2020-08-24T05:10:33.803157Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from io import StringIO\n",
    "from subprocess import Popen, PIPE, run\n",
    "from HDR_run import HDR_master\n",
    "\n",
    "home = '/Users/mahtin'\n",
    "path = '/Users/martinscience/Dropbox/Icke/Work/somVar/HDRtest'\n",
    "bam_file = f'{path}/data/002.bam '\n",
    "chrom = 'chr1'\n",
    "# chrom = ''\n",
    "pileup_file = f'{path}/data/001.chr1.pileup'\n",
    "threads = 8\n",
    "mut_file = f'{path}/data/002.csv'\n",
    "genome_split_path = os.path.join(home,'Dropbox/Icke/Work/static/genome/gatk/hg38/split')\n",
    "HDR_config = {\n",
    "    \"minAltSum\": 2,\n",
    "    \"minAltRatio\": 0.1,\n",
    "    \"maxAltRatio\": 0.85,\n",
    "    \"MINQ\": 15,\n",
    "    \"MINSIM\": .50,\n",
    "    \"PAD\": 100,\n",
    "    \"MINq\": 10,\n",
    "    \"MinAltSupport\": 5,\n",
    "    \"MinHDRCount\": 1,\n",
    "    \"pile2hotspot\": '../shell/pile2hotspot.mawk',#\n",
    "    \"pile2hotspot_chrom\": '../shell/pile2hotspot_chrom.mawk',\n",
    "    \"editbam\": '../shell/editbam.mawk',\n",
    "    \"bam2csv\": '../shell/bam2csv.mawk',\n",
    "    \"genome_split_path\": genome_split_path # the path to the folder with chrom-split genomes (chr1.fa..)\n",
    "}\n",
    "HDR_master(mut_file, bam_file=bam_file, pileup_file=pileup_file, chrom=chrom, threads=threads, HDR_config=HDR_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:07:32.114469Z",
     "start_time": "2020-08-23T14:07:31.983073Z"
    }
   },
   "outputs": [],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:25:07.814840Z",
     "start_time": "2020-08-23T19:25:07.772067Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "home = '/Users/mahtin'\n",
    "path = '/Users/mahtin/Dropbox/Icke/Work/somVar/HDRtest'\n",
    "bam_file = f'{path}/data/002.bam '\n",
    "chrom = 'chr1'\n",
    "# chrom = ''\n",
    "pileup_file = f'{path}/data/002.pileup'\n",
    "threads = 8\n",
    "mut_file = f'{path}/data/002.csv'\n",
    "mut_df = pd.read_csv(mut_file, sep='\\t').loc[:, [\n",
    "        'Chr', 'Start', 'End', 'Ref', 'Alt', 'Gene']]\n",
    "# make Chr column categorical for sorting .. and sort\n",
    "chrom_list = [f\"chr{i}\" for i in range(23)] + ['chrX', 'chrY']\n",
    "mut_df['Chr'] = pd.Categorical(mut_df['Chr'], chrom_list)\n",
    "mut_df = mut_df.sort_values(['Chr', 'Start'])\n",
    "mut_df = mut_df.query('Chr == @chrom')\n",
    "mut_df\n",
    "mut_split = np.array_split(mut_df, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:14:23.270088Z",
     "start_time": "2020-08-23T19:14:23.267394Z"
    }
   },
   "outputs": [],
   "source": [
    "mut_df = mut_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:30:19.182347Z",
     "start_time": "2020-08-23T19:30:19.170669Z"
    }
   },
   "outputs": [],
   "source": [
    "anno_df = mut_df.sort_values(['Chr', 'Start']).iloc[0:,:5]\n",
    "anno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:38:46.184923Z",
     "start_time": "2020-08-23T19:38:46.179603Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_regions(df, padding):\n",
    "    '''\n",
    "    takes a mutation list and returns a region list using padding\n",
    "    overlapping regions are reduced to one using the gap strategy\n",
    "    '''\n",
    "\n",
    "    df = df.sort_values('Start')\n",
    "    df['Start'] = df['Start'] - padding\n",
    "    df['End'] = df['End'] + padding\n",
    "    # find the break points\n",
    "    # if Start is greater than previous End (using shift), this is a gap --> df['gap'] = 1\n",
    "    df['gap'] = df['Start'].gt(df['End'].shift()).astype('int')\n",
    "    # id different reads according to gap\n",
    "    # cumulative sum does not increase at df['gap'] == 0 and so these consecutive stretches are grouped together\n",
    "    df['gap'] = df['gap'].cumsum()\n",
    "    # groupby the coverage break group and condense individual coverage islands\n",
    "    # agg has to contain the neccessary shared columns TransLength because it is needed for coverage computation\n",
    "    df = df.groupby('gap').agg({'Chr':'first','Start': 'min', 'End':'max'})\n",
    "    return df.reset_index('gap').drop(columns='gap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:37:26.582555Z",
     "start_time": "2020-08-23T19:37:26.547975Z"
    }
   },
   "outputs": [],
   "source": [
    "df = anno_df\n",
    "anno_df\n",
    "padding = 100\n",
    "df['Start'] = df['Start'] - padding\n",
    "df['End'] = df['End'] + padding\n",
    "df['gap'] = df['Start'].gt(df['End'].shift()).astype('int')\n",
    "df['gap'] = df['gap'].cumsum()\n",
    "df = df.groupby('gap').agg({'Chr':'first','Start': 'min', 'End':'max'}).reset_index().drop(columns='gap')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T19:38:49.099313Z",
     "start_time": "2020-08-23T19:38:49.076795Z"
    }
   },
   "outputs": [],
   "source": [
    "bed_df = reduce_regions(anno_df, 100)\n",
    "bed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=[\n",
    "        'Chr',\n",
    "        'Start',\n",
    "        'End',\n",
    "        'Ref',\n",
    "        'Alt',\n",
    "        'Gene',\n",
    "        'HDRcand',\n",
    "        'HDRcount',\n",
    "        'HDRinfo',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
