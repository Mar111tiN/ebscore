{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T10:12:31.006010Z",
     "start_time": "2021-04-12T10:12:31.000341Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the code\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../code')\n",
    "\n",
    "# set the paths\n",
    "home = '/Users/martinscience'\n",
    "#  home = '/Users/mahtin'\n",
    "\n",
    "\n",
    "somvar_path = os.path.join(home, \"Dropbox/Icke/Work/somVar\")\n",
    "testdata = os.path.join(somvar_path, \"testdata\")\n",
    "ebdata = os.path.join(somvar_path, \"tooldata/EBdata\")\n",
    "pon_path = os.path.join(testdata, \"PON\")\n",
    "\n",
    "static = os.path.join(home, \"Dropbox/Icke/Work/static\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AB to EB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load AB file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_df = pd.read_csv(os.path.join(ebdata, \"AB/02_A.chr7.AB\"), sep=\"\\t\")\n",
    "AB_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AB2EB import AB2EB_multi\n",
    "EB_config = {\n",
    "    \"threads\": 8\n",
    "}\n",
    "AB2EB_multi(AB_df, config=EB_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing core functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "from scipy.special import gammaln\n",
    "import math\n",
    "# the matrices for beta-binomial calculation\n",
    "KS_matrix = np.array([[1, 0, 1, 1, 0, 1, 0, 0, 0], [0, 1, -1, 0, 1, -1, 0, 0, 0]])\n",
    "gamma_reduce = np.array([1, -1, -1, -1, 1, 1, 1, -1, -1])\n",
    "\n",
    "def fisher_combination(p_values):\n",
    "\n",
    "    if 0 in p_values:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - chi2.cdf(sum([-2 * math.log(p) for p in p_values]), 4)\n",
    "\n",
    "    \n",
    "def bb_loglikelihood(params, count_matrix):\n",
    "    [a, b] = params\n",
    "    ab_matrix = np.array([1, 1, 1, a + b, a, b, a + b, a, b])\n",
    "\n",
    "    # perform matrix multiplication to get inputs to log-gamma\n",
    "    input_matrix = np.matmul(count_matrix, KS_matrix) + ab_matrix\n",
    "\n",
    "    # get corresponding log-gamma values and reduce over pon-values\n",
    "    # if count_matrix is 2d (from fitting), gammas have to be summed up\n",
    "    # if count_matrix is 1d (shape == (2,))  only use the one gamma\n",
    "\n",
    "    gamma_matrix = gammaln(input_matrix) if (count_matrix.shape == (2,)) else np.sum(gammaln(input_matrix), axis=0)\n",
    "\n",
    "    # add or subtract using gamma_reduce matrix and sum to loglikelihood (scalar)\n",
    "    log_likelihood = np.sum(gamma_matrix * gamma_reduce)\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def bb_pvalue(obs_array, AB_params):\n",
    "    \"\"\"\n",
    "    get the sum of exponentials of loglikelihoods (densities) per observation\n",
    "    params is [A,B] pair\n",
    "    \"\"\"\n",
    "    return np.exp([bb_loglikelihood(AB_params, obs) for obs in obs_array]).sum()\n",
    "\n",
    "\n",
    "def get_obs_array(t_pair):\n",
    "    '''\n",
    "    turns an array [5,9] into array of observation pairs\n",
    "       [[9, 5],\n",
    "        [9, 6],\n",
    "        [9, 7],\n",
    "        [9, 8],\n",
    "        [9, 9]]\n",
    "    '''\n",
    "    return np.array([[t_pair[1], s] for s in range(t_pair[0], t_pair[1] + 1)])\n",
    "\n",
    "\n",
    "def AB2EBscore(row):\n",
    "    \"\"\"\n",
    "    takes a df containing an AB column of shape \"A+|A=B+|B-\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # get AB params from AB string\n",
    "    AB_params = np.array([p.split(\"|\") for p in row[\"AB\"].split(\"=\")]).astype(float)\n",
    "\n",
    "    # get tumor matrix from Tumor string\n",
    "    t_matrix = np.transpose([p.split(\"-\") for p in row['Tumor'].split(\"=\")]).astype(int)\n",
    "    \n",
    "    # convert tumor matrix in observation arrays\n",
    "    obs_arrays = [get_obs_array(t_pair) for t_pair in t_matrix]\n",
    "    \n",
    "    # get the p_values for each strand\n",
    "    p_values = [bb_pvalue(obs_array, AB) for (obs_array, AB) in zip(obs_arrays, AB_params)]\n",
    "    \n",
    "    # combine p_values with fisher combination\n",
    "    EB_p = fisher_combination(p_values)\n",
    "    if EB_p < 1e-60:\n",
    "        return 60\n",
    "    if EB_p > 1.0 - 1e-10:\n",
    "        return 0\n",
    "    return -round(math.log10(EB_p), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = AB_df.iloc[7012]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB2EBscore(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get AB params\n",
    "AB_params = np.array([p.split(\"|\") for p in row[\"AB\"].split(\"=\")]).astype(float)\n",
    "AB_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tumor matrix\n",
    "t_matrix = np.transpose([p.split(\"-\") for p in row['Tumor'].split(\"=\")]).astype(int)\n",
    "t_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_arrays = [get_obs_array(t_pair) for t_pair in t_matrix]\n",
    "obs_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[bb_pvalue(obs_array, AB) for (obs_array, AB) in zip(obs_arrays, AB_params)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.optimize import fmin_l_bfgs_b as minimize_func\n",
    "from scipy.stats import chi2\n",
    "from scipy.special import gammaln\n",
    "\n",
    "\n",
    "def fisher_combination(p_values):\n",
    "\n",
    "    if 0 in p_values.values():\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - chi2.cdf(\n",
    "            sum([-2 * math.log(x) for x in p_values.values()]),\n",
    "            2 * len(p_values.values()),\n",
    "        )\n",
    "\n",
    "    \n",
    "def retrieveABdata(row):\n",
    "    # retrieve the data from the row\n",
    "    # target_s:\n",
    "    # turn string \"0-5=12-42\" into target_s:\n",
    "    # pd.Series\n",
    "    # alt+       0\n",
    "    # alt-       5\n",
    "    # depth+    12\n",
    "    # depth-    42\n",
    "    target = row[\"Tumor\"]\n",
    "    count_dict = {0: \"alt+\", 1: \"alt-\", 2: \"depth+\", 3: \"depth-\"}\n",
    "    target_split = [s for ad in target.split(\"=\") for s in ad.split(\"-\")]\n",
    "    target_s = pd.Series({count_dict[i]: v for i, v in enumerate(target_split)}).astype(\n",
    "        int\n",
    "    )\n",
    "    # params:\n",
    "    # turn string A+|B+-A-|B- into AB dict {'+':[A+, B+], '-':[A-, B-]}\n",
    "    params = row[\"AB\"]\n",
    "    AB_list = [float(ab) for s in params.split(\"=\") for ab in s.split(\"|\")]\n",
    "    AB_dict = {\"+\": AB_list[:2], \"-\": AB_list[2:]}\n",
    "    return target_s, AB_dict\n",
    "\n",
    "def bb_loglikelihood_1d(obs_row, params):\n",
    "    \"\"\"\n",
    "    specialized 1-d version of bb_loglikelihood for p_value of targets\n",
    "    copy of code is justified by omitting one if clause in the heavily used 2-d version\n",
    "    \"\"\"\n",
    "\n",
    "    [a, b] = params\n",
    "    ab_matrix = np.array([1, 1, 1, a + b, a, b, a + b, a, b])\n",
    "    # convert df into matrix for np.array operations that change dims\n",
    "    count_matrix = obs_row.values\n",
    "    # perform matrix multiplication to get inputs to log-gamma\n",
    "    input_matrix = np.matmul(count_matrix, KS_matrix) + ab_matrix\n",
    "    # get corresponding log-gamma values and reduce over pon-values\n",
    "    gamma_matrix = gammaln(input_matrix)\n",
    "    # else:\n",
    "    # gamma_matrix = np.sum(gammaln(input_matrix), axis=0)\n",
    "    # add or subtract using gamma_reduce matrix and sum to loglikelihood (scalar)\n",
    "    log_likelihood = np.sum(gamma_matrix * gamma_reduce)\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def get_obs_df(target_s, cols):\n",
    "    \"\"\"\n",
    "    turn the target_s into obs_df\n",
    "    \"\"\"\n",
    "\n",
    "    # cols is either ['depth+', 'alt+'] or ['depth-', 'alt-']\n",
    "    alt_type = cols[1]\n",
    "    # creates an observation df for each observation from depth-alt to depth-depth\n",
    "    n_minus_k = target_s[cols[0]] - target_s[alt_type]\n",
    "    # obs_df is instantiated from target_s dict with n_minus_k + 1 rows\n",
    "    obs_df = pd.DataFrame(target_s[cols].to_dict(), index=range(n_minus_k + 1))\n",
    "    # alt column is incremented using index\n",
    "    obs_df[alt_type] = obs_df[alt_type] + obs_df.index\n",
    "    return obs_df\n",
    "\n",
    "\n",
    "def bb_pvalue(obs_df, params):\n",
    "    \"\"\"\n",
    "    get the sum of exponentials of loglikelihoods (densities) per observation\n",
    "    params is strand-specific [A,B]\n",
    "    \"\"\"\n",
    "\n",
    "    # get the loglikelihood per observation\n",
    "    obs_df[\"p\"] = obs_df.apply(bb_loglikelihood_1d, params=params, axis=1)\n",
    "\n",
    "    # sum up the exponentials\n",
    "    p_value = np.exp(obs_df[\"p\"]).sum()\n",
    "\n",
    "    return p_value\n",
    "\n",
    "\n",
    "def AB2EBscore(row):\n",
    "    \"\"\"\n",
    "    takes a df containing an AB column of shape \"A+|A--B+|B-\"\"\n",
    "    \"\"\"\n",
    "    # retrieve the data from the row\n",
    "    target_s, AB_dict = retrieveABdata(row)\n",
    "    print(target_s)\n",
    "    # get the p_values for each strand\n",
    "    p_values = {}\n",
    "    p_values[\"+\"] = bb_pvalue(get_obs_df(target_s, [\"depth+\", \"alt+\"]), AB_dict[\"+\"])\n",
    "    p_values[\"-\"] = bb_pvalue(get_obs_df(target_s, [\"depth-\", \"alt-\"]), AB_dict[\"-\"])\n",
    "    # combine p_values with fisher combination\n",
    "    EB_p = fisher_combination(p_values)\n",
    "    if EB_p < 1e-60:\n",
    "        return 60\n",
    "    if EB_p > 1.0 - 1e-10:\n",
    "        return 0\n",
    "    return -round(math.log10(EB_p), 3)\n",
    "\n",
    "AB2EBscore(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_s, AB_dict = retrieveABdata(row)\n",
    "target_s\n",
    "\n",
    "obs_df = get_obs_df(target_s, [\"depth-\", \"alt-\"])\n",
    "obs_array = obs_df.values\n",
    "obs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
